{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "import numpy as np\n",
    "from qiskit.utils import algorithm_globals\n",
    "algorithm_globals.random_seed = 3142\n",
    "\n",
    "np.random.seed(algorithm_globals.random_seed)\n",
    "\n",
    "TRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = (\n",
    "    ad_hoc_data(training_size=20,\n",
    "                test_size=5,\n",
    "                n=2,\n",
    "                gap=0.3,\n",
    "                one_hot=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "FEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)\n",
    "VAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n",
    "AD_HOC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\n",
    "AD_HOC_CIRCUIT.measure_all()\n",
    "AD_HOC_CIRCUIT.decompose().draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_instance(data, variational):\n",
    "    parameters = {}\n",
    "    for i, p in enumerate(FEATURE_MAP.ordered_parameters):\n",
    "        parameters[p] = data[i]\n",
    "    for i, p in enumerate(VAR_FORM.ordered_parameters):\n",
    "        parameters[p] = variational[i]\n",
    "    return AD_HOC_CIRCUIT.assign_parameters(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parity(bitstring):\n",
    "    \"\"\"Returns 1 if parity of `bitstring` is even, otherwise 0.\"\"\"\n",
    "    hamming_weight = sum(int(k) for k in list(bitstring))\n",
    "    return (hamming_weight+1) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_probability(results):\n",
    "    shots = sum(results.values())\n",
    "    probabilities = {0: 0, 1: 0}\n",
    "    for bitstring, counts in results.items():\n",
    "        label = parity(bitstring)\n",
    "        probabilities[label] += counts / shots\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import BasicAer, execute\n",
    "\n",
    "def classification_probability(data, variational):\n",
    "    \"\"\"Classify data points using given parameters.\n",
    "    Args:\n",
    "        data (list): Set of data points to classify\n",
    "        variational (list): Parameters for `VAR_FORM`\n",
    "    Returns:\n",
    "        list[dict]: Probability of circuit classifying\n",
    "                    each data point as 0 or 1.\n",
    "    \"\"\"\n",
    "    circuits = [circuit_instance(d, variational) for d in data]\n",
    "    backend = BasicAer.get_backend('qasm_simulator')\n",
    "    results = execute(circuits, backend).result()\n",
    "    classification = [\n",
    "        label_probability(results.get_counts(c)) for c in circuits]\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(classification, expected):\n",
    "    \"\"\"Calculate accuracy of predictions using cross entropy loss.\n",
    "    Args:\n",
    "        classification (dict): Dict where keys are possible classes,\n",
    "                               and values are the probability our\n",
    "                               circuit chooses that class.\n",
    "        expected (int): Correct classification of the data point.\n",
    "\n",
    "    Returns:\n",
    "        float: Cross entropy loss\n",
    "    \"\"\"\n",
    "    p = classification.get(expected)  # Prob. of correct classification\n",
    "    return -np.log(p + 1e-10)\n",
    "\n",
    "def cost_function(data, labels, variational):\n",
    "    \"\"\"Evaluates performance of our circuit with `variational`\n",
    "    parameters on `data`.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of data points to classify\n",
    "        labels (list): List of correct labels for each data point\n",
    "        variational (list): Parameters to use in circuit\n",
    "\n",
    "    Returns:\n",
    "        float: Cost (metric of performance)\n",
    "    \"\"\"\n",
    "    classifications = classification_probability(data, variational)\n",
    "    cost = 0\n",
    "    for i, classification in enumerate(classifications):\n",
    "        cost += cross_entropy_loss(classification, labels[i])\n",
    "    cost /= len(data)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerLog:\n",
    "    \"\"\"Log to store optimizer's intermediate results\"\"\"\n",
    "    def __init__(self):\n",
    "        self.evaluations = []\n",
    "        self.parameters = []\n",
    "        self.costs = []\n",
    "    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n",
    "        \"\"\"Save intermediate results. Optimizer passes five values\n",
    "        but we ignore the last two.\"\"\"\n",
    "        self.evaluations.append(evaluation)\n",
    "        self.parameters.append(parameter)\n",
    "        self.costs.append(cost)\n",
    "\n",
    "# Set up the optimization\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "log = OptimizerLog()\n",
    "optimizer = SPSA(maxiter=100, callback=log.update)\n",
    "\n",
    "#initial_point = np.random.random(VAR_FORM.num_parameters)\n",
    "initial_point = np.array([3.28559355, 5.48514978, 5.13099949,\n",
    "                          0.88372228, 4.08885928, 2.45568528,\n",
    "                          4.92364593, 5.59032015, 3.66837805,\n",
    "                          4.84632313, 3.60713748, 2.43546])\n",
    "\n",
    "def objective_function(variational):\n",
    "    \"\"\"Cost function of circuit parameters on training data.\n",
    "    The optimizer will attempt to minimize this.\"\"\"\n",
    "    return cost_function(TRAIN_DATA, TRAIN_LABELS, variational)\n",
    "\n",
    "# Run the optimization\n",
    "result = optimizer.minimize(objective_function, initial_point)\n",
    "\n",
    "opt_var = result.x\n",
    "opt_value = result.fun\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(log.evaluations, log.costs)\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(data, labels, variational):\n",
    "    \"\"\"Gets classifier's most likely predictions and accuracy of those\n",
    "    predictions.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of data points to classify\n",
    "        labels (list): List of correct labels for each data point\n",
    "        variational (list): List of parameter values for classifier\n",
    "\n",
    "    Returns:\n",
    "        float: Average accuracy of classifier over `data`\n",
    "        list: Classifier's label predictions for each data point\n",
    "    \"\"\"\n",
    "    probability = classification_probability(data, variational)\n",
    "    predictions = [0 if p[0] >= p[1] else 1 for p in probability]\n",
    "    accuracy = 0\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == labels[i]:\n",
    "            accuracy += 1\n",
    "    accuracy /= len(labels)\n",
    "    return accuracy, predictions\n",
    "\n",
    "accuracy, predictions = test_classifier(TEST_DATA, TEST_LABELS, opt_var)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "for feature, label in zip(TRAIN_DATA, TRAIN_LABELS):\n",
    "    COLOR = 'C0' if label == 0 else 'C1'\n",
    "    plt.scatter(feature[0], feature[1],\n",
    "                marker='o', s=100, color=COLOR)\n",
    "\n",
    "for feature, label, pred in zip(TEST_DATA, TEST_LABELS, predictions):\n",
    "    COLOR = 'C0' if pred == 0 else 'C1'\n",
    "    plt.scatter(feature[0], feature[1],\n",
    "                marker='s', s=100, color=COLOR)\n",
    "    if label != pred:  # mark wrongly classified\n",
    "        plt.scatter(feature[0], feature[1], marker='o', s=500,\n",
    "                    linewidths=2.5, facecolor='none', edgecolor='C3')\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker='o', c='w', mfc='C1', label='A', ms=10),\n",
    "    Line2D([0], [0], marker='o', c='w', mfc='C0', label='B', ms=10),\n",
    "    Line2D([0], [0], marker='s', c='w', mfc='C1', label='predict A',\n",
    "           ms=10),\n",
    "    Line2D([0], [0], marker='s', c='w', mfc='C0', label='predict B',\n",
    "           ms=10),\n",
    "    Line2D([0], [0], marker='o', c='w', mfc='none', mec='C3',\n",
    "           label='wrongly classified', mew=2, ms=15)\n",
    "]\n",
    "\n",
    "plt.legend(handles=legend_elements, bbox_to_anchor=(1, 1),\n",
    "           loc='upper left')\n",
    "\n",
    "plt.title('Training & Test Data')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
